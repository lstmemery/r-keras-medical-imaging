---
title: "A First Glance at Neural Networks for Medical Computer Vision"
author: "Matthew Emery"
date: "February 12, 2019"
output: 
  revealjs::revealjs_presentation:
    theme: "night"
    css: style.css
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE}
library(tidyverse)
library(keras)
library(rprojroot)
library(fs)
```

TODO: Make font sizes larger

## Installation Guide

1. Install R 3.5:
  - Windows: https://cran.r-project.org/bin/windows/base/
  - Mac: https://cran.r-project.org/bin/macosx/
  - Ubuntu: https://cran.r-project.org/bin/linux/ubuntu/README.html
2. Install RStudio Desktop (Free): https://www.rstudio.com/products/rstudio/download/#download
3. Download and extract the code to this talk: https://github.com/lstmemery/r-keras-medical-imaging/archive/master.zip
4. Click on the .Rproj file
5. `packrat::restore()` (This will take a while, please do it before the talk)
6. `keras::install_keras()`

## Who Am I?

- Alumni of the UBC Master of Data Science Program
- Previously: Software Developer at STEMCELL Technologies
- Senior data scientist at Imbellus Inc.

<aside class="notes">Mention what Imbellus does</aside>

## Acknowledgements

 - There a bibliography at the end
 - This presentation is an adaptation of [Hello World Deep Learning in Medical Imaging](https://link.springer.com/article/10.1007/s10278-018-0079-6)
 - [Fast.ai](https://www.fast.ai/) provides a great practioner's course on deep learning

## What is Machine Learning?

- Most of the time, programmers have input data and they apply a **known function** to get an unknown output
- Machine learning is when you have input data and known outputs learn an **unknown function**
- Examples: Linear Regression, Random Forest, Neural Networks

<aside class="notes">I'm talking only about supervised learning here</aside>

## Why Should I Care About Neural Nets?

1. Training is more **end-to-end** (i.e. they can learn features about data)
2. They perform well on problems that are **in vogue** 
3. Tech companies **open-source** neural network architectures and frameworks

<aside class="notes">1. Classic algorithms rely on feature engineering</aside>
<aside class="notes">2. (Speech recognition, machine translation, computer vision)</aside>
<aside class="notes">3. It is much easier to build neural nets than it was a couple of years ago. TensorFlow started 3 years ago</aside>

## What are Neural Nets? (Please, No Math)

- They are NOT electronic brains
- They are large arrays of numbers that get multiplied by one another
- In between those multiplications, we apply a special function called an **activation function**
- We slightly adjust these numbers using a fancy version of first year calculus

<aside class="notes">1. Classic algorithms rely on </aside>

## What are Convolutional Neural Networks (CNNs)?

- CNNs are neural networks that work very well for images (and a few other applications)
- The idea is that basic features of an image (edges, corners etc.) are useful to know about regardless of where they appear in an image
- This allows the network to "share weights" between different areas of an image

![https://hackernoon.com/visualizing-parts-of-convolutional-neural-networks-using-keras-and-cats-5cc01b214e59](./img/convolution.gif)

## How do you build neural networks?
- There are many frameworks in many languages
- The most popular language is Python
- We are using the high level framework called Keras and R

## A Few Terms
- Loss Function: The function that the neural network is trying to minimize
- Batch Size: The number of images we feed into the neural net at a time
- Epochs: The number of times we see the whole training set

TODO: Get one of those dumb brain/machine images


## The Dataset

 - This is a "toy" dataset
 - Can we train a model to tell the difference between an abdominal and chest radiograph?

```{r}
# Finding Training 
root <- find_rstudio_root_file()
train_data_directory <- path(root, "data", "TRAIN")
validation_data_directory <- path(root, "data", "VAL")
```

```{r}
knitr::include_graphics(path(train_data_directory, "openI_abd_xray", "openI_1.png"))
```

```{r}
knitr::include_graphics(path(train_data_directory, "openI_CXR", "3_IM-1384-1001.png"))
```

```{r}
# Constants
img_height <- 299L
img_width <- 299L
train_samples <- 65L
validation_samples <- 10L
epochs <- 1L
batch_size <- 5L
```

## Will This Be on the Test?
- Separate your files into three groups, training, validation and testing
- Think of them as textbook exercises, midterms and the final
- If you overstudy on the only a few questions, you will have only memorized the answers without learning 
- When a machine learning algorithm, this is called overfitting
- The validation set is used at the end of each epoch to guage overfitting. 
- The neural net isn't allowed to learn from the validation set directly 
- The test set is only used after the model is completely trained.
- The test set is used to compare between models.

## Preparing images

 - Notice that these images are different sizes
 - Also the first image is slightly off-center
 - We want the network to be robust, so we will randomly change each image slightly
 - This is called **data augmentation**

```{r}
#Play around with this!
train_data_generator <- image_data_generator(
  rescale = 1/255,
  shear_range = 0.2,
  zoom_range = 0.2,
  rotation_range = 20,
  width_shift_range = 0.2,
  height_shift_range = 0.2,
  horizontal_flip = TRUE
)

validation_data_generator <- image_data_generator(
  rescale = 1/255
)
```

```{r}
train_generator <- train_data_generator$flow_from_directory(
  train_data_directory,
  target_size = c(img_height, img_width),
  batch_size = batch_size,
  class_mode = "binary"
)

validation_generator <- validation_data_generator$flow_from_directory(
  validation_data_directory,
  target_size = c(img_height, img_width),
  batch_size = batch_size,
  class_mode = "binary"
)
```

## Transfer Learning
- Google has a designed an archicture to identify images called Inception-v3
- These architectures are tested on ImageNet, a global competition to classify 1.4 million images into 1000 categories

TODO: Cite https://en.wikipedia.org/wiki/ImageNet
TODO: Add example Imagenet picture

```{r}
base_model <- application_inception_v3(
  weights = "imagenet",
  include_top = FALSE, # Keep the classification layer?
  input_shape = c(img_width, 
                  img_height, 
                  3L) # Three color channels
)
```


```{r}
for (layer in base_model$layers)
  layer$trainable <- TRUE # This let's all the weights in the model to move
```


TODO: Add explanation of transferring

```{r}
model_top <- base_model$output %>% 
  layer_global_average_pooling_2d(trainable = TRUE) %>% # TODO explain this
  layer_dense(256L, 
              activation = "relu", # max(0, x)
              trainable = TRUE) %>% 
  layer_dropout(0.5) %>% 
  layer_dense(1L,
              trainable = TRUE,
              activation = "sigmoid")
```

```{r}
full_model <- keras_model(
  inputs = base_model$input,
  outputs = model_top) %>% 
  keras::compile(
    optimizer = optimizer_adam(
      lr = 0.0001, # How much do we update weights?
      epsilon = 1e-08 # Prevents Divide by 0 errors
    ),
    loss = "binary_crossentropy",
    metrics = c("accuracy")
  )  
```

```{r}
history <- fit_generator( # Fit model
  full_model,
  generator = train_generator,
  steps_per_epoch = as.integer(train_samples / batch_size),
  epochs = epochs,
  validation_data = validation_generator,
  validation_steps = as.integer(validation_samples / batch_size)
)
```

```{r}
summary(full_model)
```


## Bibliography
